#!/usr/bin/env ruby
#MIT License
#Copyright (c) 2017-2018 phR0ze
#
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in all
#copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#SOFTWARE.

require 'fileutils'             # advanced file utils: FileUtils
require 'mkmf'                  # system utils: find_executable
require 'open-uri'              # easily read HTTP
require 'ostruct'               # OpenStruct
require 'open3'                 # Better system commands
require 'rubygems/package'      # tar
require 'yaml'                  # YAML

require_relative 'lib/core'     # ERB Handlers for different types
require_relative 'lib/config'   # Programatic file editor and command runner
require_relative 'lib/cmds'     # optparse wrapper for commands
require_relative 'lib/sys'      # System helpers

# Gems that should already be installed
begin
  require 'colorize'            # color output: colorize
  require 'filesize'            # human readable file sizes: Filesize
  require 'net/ssh'             # ssh integration: Net::SSH
  require 'net/scp'             # scp integration: Net::SCP
rescue Exception => e
  mod = e.message.split(' ').last.sub('/', '-')
  !puts("Error: install missing package with 'sudo pacman -S ruby-#{mod}'") and exit
end

class Reduce

  def initialize
    @type = OpenStruct.new({
      img: 'img',
      iso: 'iso',
      box: 'box',
      tgz: 'tgz',
      sqfs: 'sqfs'
    })
    @k = OpenStruct.new({
      all: 'all',
      base: 'base',
      boot: 'boot',
      build: 'build',
      configs: 'configs',
      command: 'command',
      cpus: 'cpus',
      conflict: 'conflict',
      container: 'container',
      desc: 'desc',
      docker: 'docker',
      entry: 'entry',
      gfxboot: 'gfxboot',
      groups: 'groups',
      i686: 'i686',
      ignore: 'ignore',
      initrd: 'initrd',
      install: 'install',
      isolinux: 'isolinux',
      kernel: 'kernel',
      label: 'label',
      layer: 'layer',
      layers: 'layers',
      machine: 'machine',
      mirrors: 'mirrors',
      multilib: 'multilib',
      name: 'name',
      noboot: 'noboot',
      off: 'off',
      packages: 'packages',
      params: 'params',
      pgp_key: 'pgp_key',
      pkg: 'pkg',
      ram: 'ram',
      type: 'type',
      vagrant: 'vagrant',
      vars: 'vars',
      vram: 'vram',
      v3d: 'v3d',
      x86_64: 'x86_64',
    })

    @rootpath = File.dirname(File.expand_path(__FILE__))
    @user = Process.uid.zero? ? Etc.getpwuid(ENV['SUDO_UID'].to_i).name : ENV['USER']
    @sudoinv = Process.uid.zero? ? "sudo -Hu #{@user} " : ''
    @runuser = "runuser #{@user} -c"

    # Load vars from base spec
    @spec = load_spec("build")
    @vars = OpenStruct.new(@spec[@k.vars])

    # Set proxy vars
    @proxyenv = {
      'ftp_proxy' => ENV['ftp_proxy'],
      'http_proxy' => ENV['http_proxy'],
      'https_proxy' => ENV['https_proxy'],
      'no_proxy' => ENV['no_proxy']
    }
    @proxy = ENV['http_proxy']
    @proxy_export = @proxy ? (@proxyenv.map{|k,v| "export #{k}=#{v}"} * ';') + ";" : nil
    @vars.proxy = @proxy

    # Set paths
    @outpath = File.join(@rootpath, 'temp')
    @workpath = File.join(@outpath, 'work')
    @pacman_path = File.join(@outpath, 'pacman')
    @tmp_dir = File.join(@workpath, 'tmp')
    @isopath = File.join(@workpath, '_iso_')
    @layers_src = File.join(@rootpath, 'layers')
    @layers_work = File.join(@workpath, 'layers')
    @vagrantpath = File.join(@rootpath, 'vagrant')

    @pacman_conf = File.join(@pacman_path, 'pacman.conf')
    @pacman_src_conf = File.join(@layers_src, 'base/etc/pacman.conf')
    @pacman_src_mirrors = File.join(@layers_src, 'base/etc/pacman.d/*.mirrorlist')
    @isoimagesdst = File.join(@isopath, @vars.distro.downcase)

    @vmlinuz_image = File.join(@isoimagesdst, 'vmlinuz')
    @ucode_image = File.join(@isoimagesdst, 'intel-ucode.img')

    @initramfs_src = File.join(@rootpath, 'boot/initramfs')
    @initramfs_work = File.join(@workpath, 'initramfs')
    @initramfs_image = File.join(@isoimagesdst, 'initramfs.img')

    @isolinux_src = File.join(@rootpath, 'boot/isolinux')
    @isolinux_work = File.join(@workpath, 'isolinux')
    @isolinux_dst = File.join(@isopath, 'isolinux')

    @packer_src = File.join(@rootpath, 'packer')
    @packer_work = File.join(@workpath, 'packer')

    @imagepaths = [
      File.join(@outpath, 'images'),
      @isoimagesdst,
      File.expand_path('~').include?('root') ? "/home/#{@user}/Downloads/images" :
        File.join(File.expand_path('~'), 'Downloads', 'images')]

    # Validate spec params
    validate = ->(name, pred){
      !puts("Error: '#{name}' is invalid in '#{@spec_file}'".colorize(:red)) and exit unless pred
    }
    validate.call('distro', @vars.distro)
    validate.call('release', @vars.release)
    validate.call('arch', [@k.i686, @k.x86_64].include?(@vars.arch))

    # Configure variables
    @vars.label = "#{@vars.distro.upcase}_#{@vars.release.gsub('.', '')}"
  end

  # Load and return the given spec
  # @param spec [String] name of the spec to load
  def load_spec(spec)
    spec_path = File.join(@rootpath, "specs/#{spec}.yml")

    begin
      spec = YAML.load_file(spec_path)
      return spec if !@spec

      # Merge with existing spec
      spec.each{|k,v| @spec[k] = v}

      # Set layer variables as needed
      @spec[@k.layers].select{|x| x[@k.type] == @k.machine}
        .each{|x| @vars["#{x[@k.name]}_layers"] = getlayers(x[@k.name]) * ','}
      @spec[@k.layers].each{|x| @vars["#{x[@k.name]}_src"] = File.join(@layers_src, x[@k.name])}
      @vars.groups = @spec[@k.layers].select{|x| x[@k.type] == @k.machine}
        .map{|x| x[@k.groups] if x[@k.groups]}.compact.uniq * ','
    rescue Exception => e
      puts("Error: invalid yaml in '#{spec_path}'".colorize(:red))
      puts(e.to_s.colorize(:red))
      raise
    end
  end

  # Create directory structure for project
  def create_dir_structure
    uid, gid = Sys.drop_privileges

    puts("Creating directory structure")
    FileUtils.mkdir_p(@pacman_path)
    FileUtils.mkdir_p(@workpath)
    FileUtils.mkdir_p(@tmp_dir)
    FileUtils.mkdir_p(@isopath)
    FileUtils.mkdir_p(@isoimagesdst)

    FileUtils.mkdir_p(@layers_work)
    FileUtils.mkdir_p(@initramfs_work)
    FileUtils.mkdir_p(@isolinux_work)
    FileUtils.mkdir_p(@isolinux_dst)

    FileUtils.mkdir_p(@imagepaths.first)
    FileUtils.mkdir_p(@packer_work)
    FileUtils.mkdir_p(@vagrantpath)

    Sys.raise_privileges(uid, gid)
  end

  # Print out distro information
  def info
    # Scrape Arch Linux kernel package
    opts = { ssl_verify_mode: 0, proxy:@proxy }
    page = open("https://www.archlinux.org/packages/core/x86_64/linux", opts).read
    @vars.kernel = page[/<title>(.*?)<\/title>/, 1][/.*linux (.*) \(x86_64\)/, 1]
    @vars.isofile = File.join(@imagepaths.first,
      "#{@vars.distro.downcase}-#{@vars.release}-#{@vars.kernel}-#{@vars.arch}.iso")

    puts("Distro: #{@vars.distro}".colorize(:green))
    puts("Release: #{@vars.release}".colorize(:green))
    puts("Arch: #{@vars.arch}".colorize(:green))
    puts("Kernel: #{@vars.kernel}".colorize(:green))
    puts("Source path: #{@rootpath}".colorize(:green))
    puts("Output path: #{@outpath}".colorize(:green))
    puts("Proxy: #{@proxyenv['http_proxy']}".colorize(:green)) if @proxy
  end

  # List components as directed
  # @param boxes [bool] list all boxes
  # @param isos [bool] list all isos
  # @param images [bool] list all docker images
  # @param all [bool] list all components
  def list(boxes:nil, isos:nil, images:nil, all:nil)
    all = all || ![boxes, isos, images].any?

    # Formatting block for images
    putimages = ->(type, live, name){
      puts("#{name.ljust(85, ' ')}Size:".colorize(:cyan))
      getimages(type, live:live).each{|k,v|
        size = v.to_s.count("a-zA-Z").zero? ? Filesize.from("#{v} B").to_s('MiB') : v
        puts("#{k.ljust(85, ' ')}#{size}")
      }
      puts
    }

    putimages.call(@type.box, false, 'Boxes:') if boxes or all
    putimages.call(@type.iso, false, 'ISOs:') if isos or all
    putimages.call(@type.img, false, 'Machine Boot Images:') if isos or all
    putimages.call(@type.sqfs, false, 'Machine Layer Images:') if isos or all
    putimages.call(@type.tgz, false, 'Container Layer Images:') if images or all
    putimages.call(@type.tgz, true, 'Container Deployed Images:') if images or all
  end

  # Clean components as directed
  # @param pacman [bool] clean pacman component
  # @param initramfs [bool] clean initramfs component
  # @param isolinux [bool] clean isolinux component
  # @param layers [bool] clean given layers
  # @param iso [bool] clean iso image
  # @param vms [bool] clean vms
  # @param all [bool] clean all components
  # @param isofull [bool] clean iso image including all machine layers
  def clean(pacman:nil, initramfs:nil, isolinux:nil, layers:nil, iso:nil, vms:nil, all:nil, isofull:nil)
    !puts("Error: no clean options specified".colorize(:red)) and
      exit unless [pacman, initramfs, isolinux, layers, iso, vms, all, isofull].any?
    !puts("Error: must be executed as root".colorize(:red)) and
      exit unless Process.uid.zero?

    # Clean all
    if all
      puts("Cleaning all...".colorize(:cyan))
      puts("Deleting #{@workpath}".colorize(:red)) if File.exist?(@workpath)
      Sys.rm_rf(@workpath)
    end

    # Clean initramfs component
    if !all and (initramfs or isofull)
      puts("Cleaning initamfs...".colorize(:cyan))
      puts("Deleting #{@initramfs_work}".colorize(:red)) if File.exist?(@initramfs_work)
      Sys.rm_rf(@initramfs_work)
      puts("Deleting #{@initramfs_image}".colorize(:red)) if File.exist?(@initramfs_image)
      Sys.rm_rf(@initramfs_image)
    end

    # Clean isolinux component
    if !all and (isolinux or layers or isofull)
      puts("Cleaning isolinux...".colorize(:cyan))
      puts("Deleting #{@isolinux_work}".colorize(:red)) if File.exist?(@isolinux_work)
      Sys.rm_rf(@isolinux_work)
      puts("Deleting #{@isolinux_dst}".colorize(:red)) if File.exist?(@isolinux_dst)
      Sys.rm_rf(@isolinux_dst)

      puts("Deleting #{@ucode_image}".colorize(:red)) if File.exist?(@ucode_image)
      File.delete(@ucode_image) if File.exist?(@ucode_image)
      puts("Deleting #{@vmlinuz_image}".colorize(:red)) if File.exist?(@vmlinuz_image)
      File.delete(@vmlinuz_image) if File.exist?(@vmlinuz_image)
    end

    # Clean given layers
    if !all and Dir.exist?(@layers_work) and (layers || isofull)
      (layers || ((all || isofull) ? Dir.children(@layers_work) : nil)).each{|layer|
        puts("Cleaning layer '#{layer}'...".colorize(:cyan))
        path = File.join(@layers_work, layer)
        puts("Deleting #{path}".colorize(:red)) if File.exist?(path)
        Sys.rm_rf(path)
        @imagepaths[0..1].each{|path|
          Dir[File.join(path, "#{layer}*")].each{|x|
            puts("Deleting #{x}".colorize(:red))
            File.delete(x)}
        }
        evalimages!(@type.tgz, layer:layer, live:true, force:true)
      }
    end

    # Clean pacman
    if pacman or all
      puts("Cleaning pacman...".colorize(:cyan))
      puts("Deleting #{@pacman_path}".colorize(:red)) if Dir.exist?(@pacman_path)
      Sys.rm_rf(@pacman_path)
    end

    # Clean iso path
    if !all and isofull
      puts("Cleaning iso path...".colorize(:cyan))
      puts("Deleting #{@isopath}".colorize(:red)) if File.exist?(@isopath)
      Sys.rm_rf(@isopath)
    end

    # Clean iso image
    if iso or layers or all or isofull
      puts("Cleaning iso image...".colorize(:cyan))
      Dir[File.join(@imagepaths.first, '*.iso')].each{|x|
        puts("Deleting #{x}".colorize(:red))
        File.delete(x)
      }
    end

    # Clean vagrant vms that are no longer deployed
    if vms or all
      puts("Cleaning vagrant vms...".colorize(:cyan))
      if File.exist?(@vagrantpath)
        vgout = `#{@sudoinv}vagrant global-status --prune`.split("\n")
        puts(vgout)
        vms = vgout.select{|x| x.include?('virtualbox')}.map{|x| x.split(' ')[1]}
        Dir[File.join(@vagrantpath, '*')].map{|x| File.basename(x)}.each{|vm|
          if !vms.include?(vm)
            path = File.join(@vagrantpath, vm)
            puts("Removing vagrant env. for missing VM #{path}".colorize(:red))
            Sys.rm_rf(path)
          end
        }
      end
    end
  end

  # Build components as directed
  # @param spec [String] cyberlinux spec to build from
  # @param initramfs [bool] build initramfs component
  # @param isolinux [bool] build isolinux component
  # @param layers [Array] build given layers
  # @param iso [bool] build iso image from whatever machine layers exist
  # @param isofull [bool] build iso image including all machine layers
  def build(spec, initramfs:nil, isolinux:nil, layers:nil, iso:nil, isofull:nil)
    opts = [initramfs, isolinux, layers, iso, isofull]
    !puts("Error: no build options specified".colorize(:red)) and exit unless opts.any?
    changed = false
    load_spec(spec)

    info
    create_dir_structure

    if opts.any?
      !puts("Error: must be executed as root".colorize(:red)) and
        exit unless Process.uid.zero?
      puts("#{'-' * 80}\nBuilding ISO components...\n#{'-' * 80}".colorize(:light_yellow))
    end

    # Build implicated layers
    changed |= build_layers(@k.build) if not (layers || []).include?(@k.build)
    layers = @spec[@k.layers].select{|x| x[@k.type] == @k.machine}.map{|x| x[@k.name]} if isofull
    layers.each{|layer| changed |= build_layers(layer)} if layers

    # Build early userspace ramdisk for install executed by isolinux
    changed |= build_initramfs if [initramfs, iso, isofull].any?

    # Build GFXBoot UI that boots initramfs installer and in turn the real kernel
    changed |= build_isolinux if [isolinux, iso, isofull].any?

    # Create ISO Hybrid CD/USB bootable image to launch isolinux via xorriso
    # Note: the eltorito-boot and eltorito-catalog appear to be paths
    # relative to the construction of the ISO which threw me off for awhile
    if [iso, isofull].any?
      puts("#{'-' * 80}\nBuilding ISO Hybrid CD/USB bootable image...\n#{'-' * 80}".colorize(:light_yellow))
      if changed or not File.exist?(@vars.isofile)
        cmd = "xorriso -as mkisofs "
        cmd += "-iso-level 3 -rock -joliet "
        cmd += "-max-iso9660-filenames -omit-period "
        cmd += "-omit-version-number "
        cmd += "-relaxed-filenames -allow-lowercase "
        cmd += "-volid \"#{@vars.label}\" "
        cmd += "-appid \"#{@vars.distro} %s\" " % 'Install/Live CD'
        cmd += "-publisher \"#{@vars.distro}\" "
        cmd += "-preparer \"#{@vars.distro}\" "
        cmd += "-eltorito-boot \"%s\" " % 'isolinux/isolinux.bin'
        cmd += "-eltorito-catalog \"%s\" " % 'isolinux/boot.cat'
        cmd += "-no-emul-boot -boot-load-size 4 -boot-info-table "
        cmd += "-isohybrid-mbr \"#{File.join(@isolinux_dst, 'isohdpfx.bin')}\" "
        cmd += "-output \"#{@vars.isofile}\" "
        cmd += "\"#{@isopath}\""
        msg = "ISO Hybrid CD/USB bootable image:\n#{@vars.isofile}"
        if Sys.exec(cmd)
          puts("Successfully built #{msg}".colorize(:green))
        else
          !puts("Error: Failed to build #{msg}".colorize(:red)) and exit
        end
      end
    end
  end

  # Create the initramfs.img
  # which provides the boot environment we will install from
  # @returns true on changed
  def build_initramfs
    create_dir_structure
    changed = false
    initramfs_digests = File.join(@initramfs_work, 'digests')

    puts("#{'-' * 80}\nBuilding initramfs image...\n#{'-' * 80}".colorize(:light_yellow))
    if syncfiles(File.basename(@initramfs_work), @initramfs_src, @initramfs_work, initramfs_digests) or
        not File.exist?(@initramfs_image)
      changed |= true
      installer = File.join(@initramfs_work, 'installer')
      installer_conf = File.join(@initramfs_work, 'installer.conf')
      mkinitcpio_conf = File.join(@initramfs_work, 'mkinitcpio.conf')

      # Resolve template
      Fedit.resolve(installer, @vars)

      # Build initramfs image in build container
      docker(@k.build, @k.build){|cont, home, cp, exec, execs, runuser|
        cp["#{installer} #{cont}:/usr/lib/initcpio/hooks"]
        cp["#{installer_conf} #{cont}:/usr/lib/initcpio/install/installer"]
        cp["#{mkinitcpio_conf} #{cont}:/etc"]

        puts("Creating #{@initramfs_image}...".colorize(:cyan))
        initramfs = File.join('/root', File.basename(@initramfs_image))
        kernelstr = `#{execs} ls /lib/modules`.split("\n").sort.first
        puts("Using kernel: #{kernelstr}".colorize(:green))

        exec["mkinitcpio -k #{kernelstr} -g #{initramfs}"]
        cp["#{cont}:#{initramfs} #{@initramfs_image}"]
        puts("Successfully built initramfs image #{@initramfs_image}".colorize(:green))
      }
    end

    return changed
  end

  # Build bootable ISOLinux with USB support
  # @returns true on changed
  def build_isolinux
    create_dir_structure
    changed = false
    layers = @spec[@k.layers].select{|x| x[@k.boot]}.reverse
    isolinux_digests = File.join(@isolinux_work, 'digests')

    puts("#{'-' * 80}\nBuilding isolinux with gfxboot ui...\n#{'-' * 80}".colorize(:light_yellow))
    if syncfiles(File.basename(@k.isolinux), @isolinux_src, @isolinux_work, isolinux_digests) or
        not File.exist?(File.join(@isolinux_dst, 'isohdpfx.bin'))
      changed |= true

      # Inject boot menu items from layers
      File.open(File.join(@isolinux_work, 'isolinux.msg'), 'a'){|f|
        layers.each{|layer| layer[@k.boot].each{|x|
          f << "#{(x[@k.label] || layer[@k.name]).ljust(21)}- #{x[@k.entry]}\n"}}}
      Fedit.resolve(File.join(@isolinux_work, 'isolinux.msg'), @vars)
      File.open(File.join(@isolinux_work, 'isolinux.cfg'), 'a'){|f|
        layers.each{|layer| layer[@k.boot].each{|x|
          f << "label #{x[@k.label] || layer[@k.name]}\n"
          f << "  kernel #{x[@k.kernel]}\n"
          f << "  append initrd=#{x[@k.initrd]}\n" if x[@k.initrd]}}}
      Fedit.resolve(File.join(@isolinux_work, 'isolinux.cfg'), @vars)

      # Inject gfxboot configuration
      File.open(File.join(@isolinux_work, 'gfxboot/data/gfxboot.cfg'), 'a'){|f|
        f << "isolinux.labels=%s\n" % (layers.map{|x| x[@k.boot].map{|y| y[@k.label] || x[@k.name]}}.flatten * ',')
        f << "gfxboot.menu.names=%s\n" % (layers.map{|x| x[@k.boot].map{|y| y[@k.entry]}}.flatten * ',')
        f << "gfx.noboot=%s\n" % (layers.map{|x| x[@k.boot].map{|y| (y[@k.label] || x[@k.name]) if y[@k.noboot]}}.flatten.compact * ',')
      }
      Fedit.resolve(File.join(@isolinux_work, 'gfxboot/data/gfxboot.cfg'), @vars)

      # Compile GFXboot ui and extract isolinux files
      docker(@k.build, @k.build){|cont, home, cp, exec, execs, runuser|

        puts("Compile and extract isolinux UI...".colorize(:cyan))
        cp["#{File.join(@isolinux_work, 'gfxboot')} #{cont}:#{home}"]
        exec["chown -R #{@k.build}:#{@k.build} #{home}"]
        runuser["cd #{home}/gfxboot && make clean && make"]
        cp["#{cont}:#{home}/gfxboot/build/gfxboot.ui #{@isolinux_work}"]

        # https://wiki.archlinux.org/index.php/syslinux
        puts("Extract isolinux binaries/modules...".colorize(:cyan))
        cp["#{cont}:/usr/lib/syslinux/bios/isolinux.bin #{@isolinux_work}"] # El Torito Boot loader
        cp["#{cont}:/usr/lib/syslinux/bios/isohdpfx.bin #{@isolinux_work}"] # USB support
        cp["#{cont}:/usr/lib/syslinux/bios/ldlinux.c32 #{@isolinux_work}"]  # BIOS support
        cp["#{cont}:/usr/lib/syslinux/bios/gfxboot.c32 #{@isolinux_work}"]  # High-graphics menu support
        cp["#{cont}:/usr/lib/syslinux/bios/mboot.c32 #{@isolinux_work}"]    # Layer image loading support
        cp["#{cont}:/usr/lib/syslinux/bios/chain.c32 #{@isolinux_work}"]    # Chain load HDT and Memory Test
        cp["#{cont}:/usr/lib/syslinux/bios/whichsys.c32 #{@isolinux_work}"] # Chain load HDT and Memory Test
        cp["#{cont}:/usr/lib/syslinux/bios/libcom32.c32 #{@isolinux_work}"] # Chain load HDT and Memory Test
        cp["#{cont}:/usr/lib/syslinux/bios/hdt.c32 #{@isolinux_work}"]      # Hardware Detection Tool dep
        cp["#{cont}:/usr/lib/syslinux/bios/libmenu.c32 #{@isolinux_work}"]  # Hardware Detection Tool dep
        cp["#{cont}:/usr/lib/syslinux/bios/libutil.c32 #{@isolinux_work}"]  # Hardware Detection Tool dep
        cp["#{cont}:/usr/lib/syslinux/bios/libgpl.c32 #{@isolinux_work}"]   # Hardware Detection Tool dep
        cp["#{cont}:/usr/share/hwdata/pci.ids #{@isolinux_work}"]           # Hardware Detection Tool dep
        cp["#{cont}:/boot/memtest86+/memtest.bin #{@isolinux_work}/memtest"]# Memory test
        cp["#{cont}:/boot/intel-ucode.img #{@ucode_image}"]                 # Intel microcode updates
        cp["#{cont}:/boot/vmlinuz-linux #{@vmlinuz_image}"]                 # Linux kernel
      }

      puts("Copying isolinux destination files...".colorize(:cyan))
      Dir.glob(File.join(@isolinux_work, '**/*'), File::FNM_DOTMATCH).each{|x|
        if File.basename(x) != 'digests' and not x.include?("gfxboot/") and File.file?(x)
          dst = x.sub(@isolinux_work, @isolinux_dst)
          puts("Copying to #{dst}")
          FileUtils.mkdir_p(File.dirname(dst))
          FileUtils.cp(x, dst)
        end
      }

      puts("Successfully built isolinux".colorize(:green))
    end

    return changed
  end

  # Pack the given layer or all layers if no specific layer given
  # @param layers [list] layers to pack into an image else all
  # @param disksize [int] disk size to use for pack
  # @param force [bool] pack even if already exists
  def pack(layers, disksize:nil, force:nil)
    _layers = @spec[@k.layers].select{|x| x[@k.boot]}
    layers = layers || _layers.reject{|x| x[@k.name] == 'live' or not x[@k.boot].any?{|y| y[@k.initrd]}}
    puts("#{'-' * 80}\nPacking layers #{layers * ','}\n#{'-' * 80}".colorize(:light_yellow))
    !puts("Error: must be executed as non-root user".colorize(:red)) and
      exit unless not Process.uid.zero?
    create_dir_structure

    # Ensure we have the right binaries available
    !puts("Ensure 'packer' https://www.packer.io/downloads.html is in the path".colorize(:red)) and
      exit unless find_executable('packer')
    !puts("Please install 'virtualbox' via 'sudo pacman -S virtualbox'".colorize(:red)) and
      exit unless find_executable('vboxmanage')

    # Locate latest iso
    isos = getimages(@type.iso).keys
    !puts("Error: no ISOs found".colorize(:red)) and exit unless isos.any?
    @vars.isofile = isos.shift

    @vars.release = @vars.isofile[/-(.*?)-/, 1]
    puts("Release: #{@vars.release}".colorize(:cyan))
    puts("ISO: #{@vars.isofile}".colorize(:cyan))

    # Configure host-only network
    config_network = "#{@sudoinv}vboxmanage hostonlyif ipconfig "
    config_network += "#{@vars.netname} -ip #{@vars.netip} -netmask #{@vars.subnet}"
    if not Sys.exec(config_network, die:false)
      Sys.exec("#{@sudoinv}vboxmanage hostonlyif create")
      Sys.exec(config_network)
    end

    # Pack implicated layers into vagrant boxes
    installables = _layers.map{|x| x[@k.boot].map{|y| x[@k.name] if y[@k.initrd]}}.reverse.flatten.compact
    layers.each do |layer|

      # Remove old boxes and/or skip if current
      image = evalimages!(@type.box, layer:layer, force:force)
      !puts("Box #{image} already exists".colorize(:green)) and next if image

      # Clean up build artifacts and prep for build
      puts("Building vagrant image with packer for layer '#{layer}'".colorize(:cyan))
      output_dir = File.join(@packer_work, layer)
      puts("Removing old packer artifacts at #{output_dir}".colorize(:red))
      rm_rf(output_dir)

      # Copy over and resolve packer template and scripts
      puts("Copy over and resolve packer template and scripts".colorize(:cyan))
      Dir.glob(File.join(@packer_src, '*.sh')).each{|x|
        FileUtils.cp(x, @packer_work)
        Fedit.resolve(File.join(@packer_work, File.basename(x)), @vars)
      }

      template = File.join(@packer_work, "#{layer}.json")
      FileUtils.cp(File.join(@packer_src, 'packer.json'), template)
      @vars.layer = layer
      @vars.disksize = disksize || '40000'
      @vars.downs = ['"<down>"'] * installables.index(layer) * ','
      Fedit.resolve(template, @vars)

      # Create a new vagrant image for the given layer
      puts("Building vagrant image using packer".colorize(:cyan))
      pwd = Dir.pwd and Dir.chdir(@packer_work)
      Sys.exec("packer build -only=virtualbox-iso #{layer}.json")
    end
  end

  # Deploy vagrant node/s
  # @param layer [string] layer to deploy
  # @param name [string] name to give the specific node/container being created
  # @param run [string] run the container with default run
  # @param exec [string] specific command to run in the container
  # @param nodes [list] list of node ids to deploy
  # @param ipv6 [bool] enable ipv6 on the node/s being deployed
  # @param vagrantfile [bool] export the vagrant file only
  # @param force [bool] deploy even if already exists
  def deploy(layer, name:nil, run:nil, exec:nil, nodes:nil, ipv6:nil, vagrantfile:nil, force:nil)
    puts("#{'-' * 80}\nDeploying layer '#{layer}'\n#{'-' * 80}".colorize(:light_yellow))
    create_dir_structure
    layer_yml = getlayer(layer)

    # Deploy vagrant VM
    #---------------------------------------------------------------------------
    if layer_yml[@k.type] == @k.machine
      uid, gid = Sys.drop_privileges

      # Check that vagrant is on the path and clean previously deployed VMs
      !puts("Ensure 'vagrant' https://www.vagrantup.com/downloads.html is in the path".colorize(:red)) and
        exit unless find_executable('vagrant')
      clean(vms:true)

      # Choose a vagrant box to use and update registry if needed
      vagrant_box = layer
      box = getimages(@type.box, layer:layer).keys.shift
      if !box
        vagrant_box = "phR0ze/cyberlinux-#{layer}"
        puts("Downloading '#{vagrant_box}' from vagrantup.com".colorize(:cyan))
      else
        !puts("Error: no box found for #{layer}, please pack the box first".colorize(:red)) and exit unless box
        puts("Updating vagrant registry for '#{layer}'".colorize(:cyan))
        Sys.exec("#{@sudoinv}vagrant box add #{layer} #{box} --force")
      end

      # Configure host-only network
      !puts("Ensure 'virtualbox' https://www.virtualbox.org/wiki/Downloads is in the path".colorize(:red)) and
        exit unless find_executable('vboxmanage')
      config_network = "#{@sudoinv}vboxmanage hostonlyif ipconfig "
      config_network += "#{@vars.netname} -ip #{@vars.netip} -netmask #{@vars.subnet}"
      if not Sys.exec(config_network, die:false)
        Sys.exec("#{@sudoinv}vboxmanage hostonlyif create")
        Sys.exec(config_network)
      end

      # Generate vagrant node parameters
      #---------------------------------------------------------------------------
      specs = []
      (nodes || [rand(2..254)]).each do |node|
        host = name || vagrant_box
        host = "#{host}#{node.to_s}".gsub(' ', '-').gsub('/', '-').gsub('_', '-')
        spec = {
          host: host,
          ip: "#{@vars.netip[0..-2]}#{node}/24",
          box: vagrant_box,
          cpus: layer_yml[@k.vagrant][@k.cpus] || 1,
          ram: layer_yml[@k.vagrant][@k.ram] || 512,
          vram: layer_yml[@k.vagrant][@k.vram] || 8,
          net: @vars.netname,
          v3d: layer_yml[@k.vagrant][@k.v3d] || @k.off,
          proxy: @proxyenv['http_proxy'],
          no_proxy: @proxyenv['no_proxy'],
          ipv6: ipv6
        }
        specs << spec
        puts("Generating node: #{spec.to_s}".colorize(:cyan))
      end

      # Create Vagrantfile for deployment
      vagrantfile_path = File.join(@vagrantpath, 'Vagrantfile')
      FileUtils.cp(File.join(@packer_src, 'Vagrantfile'), vagrantfile_path)
      @vars.nodes = specs.map{|x| '  ' + x.to_s} * ",\n"
      Fedit.resolve(vagrantfile_path, @vars)

      # Initialize a new vagrant instance
      #-----------------------------------------------------------------------
      if not vagrantfile
        puts("Initializing vagrant node from layer '#{layer}'".colorize(:cyan))
        vmpath = File.expand_path(FileUtils.mkdir_p(File.join(@vagrantpath, specs.first[:host])).shift)
        FileUtils.cp(vagrantfile_path, vmpath)
        File.delete(vagrantfile_path)

        # Weird UI issue in that X apps can't open display :0 until reboot
        Dir.chdir(vmpath)
        Sys.exec("#{@sudoinv}vagrant up")
        Sys.exec("#{@sudoinv}vagrant reload")
      end

      Sys.raise_privileges(uid, gid)

    # Deploy docker container
    #---------------------------------------------------------------------------
    elsif layer_yml[@k.type] == @k.container
      !puts("Error: must be executed as root".colorize(:red)) and
        exit unless Process.uid.zero?

      # Remove old 'live' images or skip if current
      image = evalimages!(@type.tgz, layer:layer, live:true, force:force)
      puts("Image #{image} already exists".colorize(:green)) if image

      # Load disk image if it exists
      if not image
        image = evalimages!(@type.tgz, layer:layer, live:false)
        image ? puts("Image #{image} exists importing".colorize(:green)) :
          !puts("Error: need to first build image '#{image}'".colorize(:red)) and exit
        Sys.exec("cat #{image} | docker import - #{File.basename(image, '.*')}:latest")
        image = File.basename(image, '.*')
      end

      # Run container
      #-------------------------------------------------------------------------
      if run or exec

        # Get docker params
        params = []
        layers = getlayers(layer).reverse[0..-1].each{|x|
          docker = getlayer(x)[@k.docker]
          params << docker[@k.params] if docker[@k.params]
        }
        puts("docker: using params #{params}".colorize(:cyan))

        # Run docker container
        # Ex: docker run --rm --name dev66 -h dev66 -e TERM=xterm build-1.0.59 bash -c "while :; do sleep 5; done"
        cont = name || 'dev'
        env = '' and @proxyenv.each{|k,v| env << "-e #{k}=#{v} " if v}
        params = exec ? "-it #{env} #{image} #{exec}" :
          (params << "#{image} #{layer_yml[@k.docker][@k.command]}").flatten * ' '
        begin
          Sys.exec("docker run --rm --name #{cont} --hostname #{cont} #{params}", die:false)
        ensure
          exists = `docker ps -a --format "{{.Names}}"`.split("\n").find{|x| x == cont}
          Sys.exec("docker kill #{cont}") if exists
        end
      end
    end
  end

  # Build the implicated layers
  # @param target_layer [string] specific layer to build
  # @returns true if changed
  def build_layers(target_layer)
    changed = false
    layers = @spec[@k.layers].map{|x| x[@k.name]}
    !puts("Error: Layer 'build' name not allowed") and exit if layers.include?(@k.build)
    !puts("Error: Layer '#{target_layer}' doesn't exist".colorize(:red)) and
      exit unless (layers + [nil, @k.build]).include?(target_layer)
    layers = getlayers(target_layer).reverse
    create_dir_structure

    layers.each do |layer|
      layer_changed = false
      layer_deps = getlayers(layer)[1..-1]
      layer_src = File.join(@layers_src, layer)
      layer_work = FileUtils.mkdir_p(File.join(@layers_work, layer)).shift
      layer_digests = File.join(layer_work, 'digests')
      layer_yml = getlayer(layer)
      layer_image = layer_yml[@k.type] == @k.machine ? File.join(@isoimagesdst, "#{layer}.sqfs") :
        File.join(@imagepaths.first, "#{layer}-#{@vars.release}.tgz")
      puts("#{'-' * 80}\nBuilding layer '#{layer}'\n#{'-' * 80}".colorize(:light_yellow))

      begin
        # Mount all dependent layers starting with base
        # Note: lowerdirs stacked from right to left (e.g. heavy, lite, base)
        if layer_deps.any?
          puts("Mount layer dependencies #{layer_deps} for layer '#{layer}'".colorize(:cyan))
          Sys.exec("mount -t overlay -o lowerdir=%s,upperdir=%s,workdir=%s none %s" %
            [layer_deps.map{|x| File.join(@layers_work, x)} * ':', layer_work, @tmp_dir, layer_work])
        end

        # Install layer specific packages via pacman
        layer_changed |= installpkgs(layer, layer_yml, layer_work)

        # Copy over all layer data if it exists
        layer_changed |= syncfiles(layer, layer_src, layer_work, layer_digests)

        # Apply file manipulations
        puts("Applying configs...".colorize(:cyan))
        changedfile = File.join(layer_work, 'changed')
        if layer_changed or not File.exist?(changedfile) or not File.exist?(layer_image)
          vars = layer_yml[@k.vars] ? @vars.to_h.merge(layer_yml[@k.vars]) : @vars
          layer_changed |= Change.apply(layer_yml[@k.configs] || [],
            OpenStruct.new({root: layer_work, vars: vars, configs: @spec[@k.configs]}))
          File.open(changedfile, 'w'){|f|}
        end

        # Build layer image if needed
        if layer_changed or not File.exist?(layer_image)
          puts("Creating #{layer_image}...".colorize(:cyan))
          Sys.umount(layer_work, retries:10) if layer_yml[@k.type] == @k.machine
          relocate_tracking_files(layer_work)

          # Create squashfs image for machine layers
          if layer_yml[@k.type] == @k.machine
            Sys.exec("mksquashfs #{layer_work} #{layer_image} -noappend -comp xz -b 256K -Xbcj x86")
          else
            # Create compressed tarball for container layers
            Sys.exec("tar --numeric-owner --xattrs --acls -C #{layer_work} -czf #{layer_image} .")
          end

          puts("Successfully built #{layer_image}".colorize(:green))
          relocate_tracking_files(layer_work, restore:true)
          layer_changed |= true
        else
          puts("Image already built #{layer_image}".colorize(:green))
        end

      ensure
        # Ensure joined file system is unmounted
        Sys.umount(layer_work, retries:10)
        rm_rf(File.join(@tmp_dir, '*'))
      end
      changed |= layer_changed
    end

    return changed
  end

  # Update pacman for use separate from the host
  # Creates configuration, seeds keys and updates databases
  def update_pacman

    # Prepare pacman for use
    if !File.exist?(@pacman_conf)

      # Configure pacmaan
      Sys.exec("cp -a #{@pacman_src_conf} #{@pacman_path}")
      Sys.exec("cp -a #{@pacman_src_mirrors} #{@pacman_path}")
      Fedit.replace(@pacman_conf, /(Architecture = ).*/, "\\1#{@vars.arch}")
      Fedit.replace(@pacman_conf, /#(DBPath\s+= ).*/, "\\1#{@pacman_path}")
      Fedit.replace(@pacman_conf, /#(CacheDir\s+= ).*/, "\\1#{File.join(@pacman_path, 'cache')}")
      Fedit.replace(@pacman_conf, /#(LogFile\s+= ).*/, "\\1#{File.join(@pacman_path, 'pacman.log')}")
      Fedit.replace(@pacman_conf, /#(GPGDir\s+= ).*/, "\\1#{File.join(@pacman_path, 'gnupg')}")
      Fedit.replace(@pacman_conf, /#(HookDir\s+= ).*/, "\\1#{File.join(@pacman_path, 'hooks')}")
      Fedit.replace(@pacman_conf, /.*(\/.*mirrorlist).*/, "Include = #{@pacman_path}\\1")

      # Populate pacman keys
      repos = Dir[File.join(@pacman_path, "*.mirrorlist")].map{|x| File.basename(x, '.mirrorlist')}
      Sys.exec("pacman-key --config #{@pacman_conf} --init")
      Sys.exec("pacman-key --config #{@pacman_conf} --populate #{repos * ' '}")
    end

    # Update pacman databases
    #Sys.exec("pacman --config #{@pacman_conf} -Sy")
    exit
    #rm_rf(File.join(@pacman_path, 'var/lib/pacman/sync/*.sig'))

  end

  # Install packages for the given layer
  # @param layer [string] layer name to work with
  # @param layer_yml [yml] layer yaml to work with
  # @param layer_work [string] the directory where to install the layer packages to
  # @returns true if any pkgs were installed else false
  def installpkgs(layer, layer_yml, layer_work)
    msg = "Installing packages for '#{layer}'..."
    pkgfile = File.join(layer_work, 'packages')

    # Handle packages differently based on type
    #---------------------------------------------------------------------------
    all_pkgs = getpkgs(layer_yml)
    pkgs = {
      reg: all_pkgs.map{|x| x[@k.pkg] if !x[@k.ignore]}.compact,
      ignore: all_pkgs.map{|x| x[@k.pkg] if x[@k.ignore]}.compact,
      conflict: all_pkgs.map{|x| "CONFLICT:#{x[@k.conflict]}" if x[@k.conflict]}.compact
    }

    # Filter out already installed packages
    #---------------------------------------------------------------------------
    if File.exist?(pkgfile)
      puts("Filtering out packages that are already installed".colorize(:cyan))
      installed_pkgs = nil
      File.open(pkgfile){|f| installed_pkgs = f.readlines.map{|x| x.strip}}
      [:reg, :conflict].each{|x| pkgs[x] = pkgs[x].select{|y| not installed_pkgs.include?(y)}}
    end

    # Install any missing packages
    #---------------------------------------------------------------------------
    if pkgs.any?{|k,v| v.any? if k != :conflict and k != :ignore}
      puts("#{msg}".colorize(:cyan))
      puts("Packages: #{pkgs[:reg]}")
      puts("Ignore Pkgs: #{pkgs[:ignore]}")
      puts("Conflict Pkgs: #{pkgs[:conflict]}")

      # pacstrap replacement
      if pkgs[:conflict].any? or pkgs[:reg].any?
        begin
          update_pacman

          # Remove these packages first
          if pkgs[:conflict].any?
            puts("Removing conflicting packages for '#{layer}'...".colorize(:cyan))
            conflicts = pkgs[:conflict].map{|x| x.split(':').last} * ' '
            !puts("Error: Failed to remove packages".colorize(:red)) and
              exit unless Sys.exec("pacman -Rn -r #{layer_work} -d -d --noconfirm #{conflicts}", die:false)
          end

          # Install normal packages
          if pkgs[:reg].any?
            puts("Installing regular packages for '#{layer}'...".colorize(:cyan))
            cmd = ['pacstrap', '-GMcd', layer_work, '--config', pacman_conf, '--needed', *pkgs[:reg]]
            cmd += ['--ignore', pkgs[:ignore] * ','] if pkgs[:ignore].any?
            !puts("Error: Failed to install packages correctly".colorize(:red)) and
              exit unless Sys.exec(cmd, env:@proxyenv)
          end

        ensure
          Sys.umount(File.join(layer_work, 'dev'), retries: 10)
        end
      end

#      # Clean up left artifacts from installs to leave prestine layer
#      puts("Cleaning up artifacts that may be left over from installs".colorize(:cyan))
#      Sys.exec("find #{layer_work} -name *.pacnew -name *.pacsave -name *.pacorig -delete")
#
#      # Remove pacman transient data
#      Sys.exec("find #{File.join(layer_work, 'var/lib/pacman')} -maxdepth 1 -type f -delete")
#      rm_rf(File.join(layer_work, 'var/lib/pacman/sync/*'))
#
#      # Remove all files from logging or packaging but leave empty dirs
#      Sys.exec("find #{File.join(layer_work, 'var/log')} -type f -delete")
#      Sys.exec("find #{File.join(layer_work, 'var/cache/pacman/pkg')} -type f -delete")
#
#      # Remove pacman GnuPG keys for a fresh start
#      rm_rf(File.join(layer_work, 'etc/pacman.d/gnupg'))
#
      # Remove all temporary files and dirs
      rm_rf(File.join(layer_work, 'var/tmp/*'))
      rm_rf(File.join(layer_work, 'tmp/*'))

      # Avoid "Failed to start Create Volatile Files and Directories"
      rm_rf(File.join(layer_work, 'var/log/journal'))

      # Update list of packages that were installed
      File.open(pkgfile, 'a'){|f| f.puts(pkgs[:reg])}
    else
      puts("#{msg}skipping".colorize(:cyan))
    end

    return pkgs.any?{|k,v| v.any? if k != :conflict and k != :ignore }
  end

  # Get packages for the given layer
  # @param layer_yml [yml] layer yaml to work with or all if nil
  # @returns list of packages for the given layer or all packages
  def getpkgs(layer_yml)
    result = {}
    layers = layer_yml ? [layer_yml] : @spec[@k.layers]

    # Detect multilib value
    multilib = layers.any?{|x| x[@k.multilib]}
    puts("Multilib: #{multilib} for #{layers.map{|x| "'#{x[@k.name]}'"} * ','}".colorize(:cyan))

    # Get all packages for given layers
    layers.each{|layer|
      all_pkgs = (layer[@k.packages] || [])
      resolve_pkgsets = ->(pkgs){
        return pkgs.map{|x|
          if x[@k.install] || (x[@k.ignore] && !x[@k.pkg])
            pkgkey = x[@k.install] || x[@k.ignore]
            pkgset = @spec[@k.packages][pkgkey].clone
            !puts("Error: missing package set '#{pkgkey}'".colorize(:red)) and exit unless pkgset
            # TODO: when multilib=true and arch is i686 then do opposite
            pkgset.reject!{|y| multilib ? y[@k.multilib] == false : y[@k.multilib]} if x[@k.install]
            pkgset.each{|y| y[@k.ignore] = true } if x[@k.ignore]
            pkgset
          else
            x
          end
        }.flatten}
      (0..1).each{|i| all_pkgs = resolve_pkgsets.call(all_pkgs)}

      # Remove duplicates
      all_pkgs.uniq!

      result[layer[@k.name]] = all_pkgs
    }

    return result.length == 1 ? result.values.first : result
  end

  # Spins up indicated container and executes the given block
  # in the container then terminates the container.
  # @param layer [string] container to use
  # @param user [string] user to work with
  # @param block [block] block of code to execute
  def docker(layer, user, &block)

    # Spin up given container and wait for it to be ready
    #---------------------------------------------------------------------------
    cont = "dev#{rand(10..99)}"
    thread = Thread.new{deploy(layer, name:cont, run:true)}
    (1..100).each{|i|
      if not `docker ps`.include?(cont)
        puts("Waiting for container '#{cont}' to be ready...") if i % 2 == 0
        sleep(1)
      else
        break
      end
    }

    # Execute in container
    #---------------------------------------------------------------------------
    vars = '' and @proxyenv.each{|k,v| vars << "export #{k}=#{v} && " if v}
    home = user == 'root' ? "/root" : "/home/#{user}"
    cp = ->(cmd){Sys.exec("docker cp #{cmd}")}
    exec = ->(cmd){Sys.exec("docker exec #{cont} bash -c \"#{vars}#{cmd.gsub(/"/, '\"')}\"")}
    execs = "docker exec #{cont}"
    runuser = ->(cmd){Sys.exec("docker exec #{cont} runuser #{user} -c \"#{vars}#{cmd.gsub(/"/, '\"')}\"")}
    block.call(cont, home, cp, exec, execs, runuser)

    # Shutdown container
    #---------------------------------------------------------------------------
    thread.kill
    thread.join
  end

  # Syncs the source and work directories for a given layer
  # @param layer [string] layer to work with
  # @param layer_src [path] layer source directory to work with
  # @param layer_work [path] layer work directory to work with
  # @param layer_digests [path] layer digests file
  # @param block [block] block of code to execute
  def syncfiles(layer, layer_src, layer_work, layer_digests, &block)
    changed = false
    return changed if not File.exist?(layer_src)

    msg = "Syncing from #{layer_src}"
    files = Dir.glob(File.join(layer_src, '**/*'), File::FNM_DOTMATCH).reject{|x| File.directory?(x)}
    newfiles, modifiedfiles, deletedfiles = Fedit.digests_changed(layer, layer_digests, files)
    if newfiles.any? or modifiedfiles.any? or deletedfiles.any? or not File.exist?(layer_digests)
      changed |= true
      puts(msg.colorize(:cyan))

      # Remove files that no longer exist from layer directory not data
      deletedfiles.each{|x|
        target = x.sub(layer_src, layer_work)
        puts("Deleting #{target}".colorize(:red))
        File.delete(target)
      }

      # Copy over files from data dir to layer dir
      if File.exist?(layer_src)
        files.each{|x|
          puts("Copying: #{x.sub(layer_src, '...')}")
          FileUtils.mkdir_p(File.dirname(x.sub(layer_src, layer_work)))
          FileUtils.cp(x, x.sub(layer_src, layer_work))}
      end

      # Copy user files to root as well
      skelpath = File.join(layer_src, 'etc/skel')
      if File.exist?(skelpath)
        puts("Copying from #{skelpath}".colorize(:cyan))
        Dir.glob(File.join(skelpath, '/**/*'), File::FNM_DOTMATCH).reject{|x| File.directory?(x)}.each{|x|
          puts("Copying: #{x.sub(layer_src, '...')} => #{x.sub(skelpath, '.../root')}")
          FileUtils.mkdir_p(File.dirname(x.sub(layer_src, layer_work).sub('etc/skel', 'root')))
          FileUtils.cp(x, x.sub(layer_src, layer_work).sub('etc/skel', 'root'))}
      end

      # Execute block
      block.call if block

      # Update digests
      Fedit.update_digests(layer, layer_digests, files)
    else
      puts("#{msg}...skipping".colorize(:cyan))
    end

    puts("Completed constructing/modifiying files for '#{layer}' layer".colorize(:green))

    return changed
  end

  # Evaluate images matching type and layer; removing if stale
  # @param type [string] image type to get
  # @param layer [string] layer to get image for or all
  # @param live [bool] evaluate live(true) vs disk(false)
  # @param force [bool] remove images matching conditions
  # @returns image matching the version
  def evalimages!(type, layer:nil, live:nil, force:nil)
    image_exists = nil
    curver = @vars.release.split('.').map{|x| x.to_i}

    getimages(type, layer:layer, live:live).keys.each{|image|
      puts("Evaluating '#{live ? 'live' : 'disk'}' image #{image}".colorize(:cyan))
      name = live ? image[/-(.*)/, 1] : image[/-(.*?)\.#{type}/, 1]
      imagever = name.split('.').map{|x| x.to_i}
      if force or (imagever <=> curver) == -1
        puts("Removing image '#{live ? 'live' : 'disk'}' #{image} - #{force ? 'forced' : 'outdated'}".colorize(:red))
        if not live
          File.delete(image)
        elsif type == @type.tgz

          # Remove any old containers that depend on that image
          cntrs = `sudo docker ps -a --format "{{.Image}}:{{.ID}}"`.split("\n")
            .select{|x| x.start_with?(image)}
          cntrs.each{|x| Sys.exec("sudo docker rm #{x.split(':')[1]}")}

          # Remove image
          Sys.exec("sudo docker rmi #{image} --force")
        end
      else
        image_exists = image
      end
    }

    return image_exists
  end

  # Get all images sorted newest to oldest
  # @param type [string] image type to get
  # @param layer [string] layer to get image for or all
  # @param live [bool] get live(true) vs disk(false)
  # @param die [bool] die on error
  # @returns all images sorted by version and optionally filtered by layer
  def getimages(type, layer:nil, live:nil, die:false)
    image_maps = {}

    # Get deployed image data
    #---------------------------------------------------------------------------
    if live and type == @type.tgz
      images = {}
      `sudo docker images --format "{{.Repository}}:{{.Size}}"`.split("\n")
        .select{|x| layer ? x.start_with?("#{layer}-") : true }
        .map{|x| x.split(':')}.each{|x| images[x.first] = x.last}
      images.keys.sort_by{|x| (x[/-(\d+\.\d+\.\d+).*/, 1] || "<none>.").split('.').map{|y| y.to_i} }
        .reverse!.each{|x| image_maps[x] = images[x]}

    # Get disk image data
    #---------------------------------------------------------------------------
    elsif not live

      # Get all files of the given type from the watched locations
      files = []
      files += @imagepaths.map{|x| File.exist?(x) ? Dir[File.join(x, "*.#{type}")] : []}.flatten

      # For isos and boxes filter on files that contain the distro name
      if [@type.box, @type.iso].include?(type)
        files.delete_if{|x| !File.basename(x).start_with?(@vars.distro)}
      end

      # Sort the resulting list by version
      images = layer ? files.select{|x| x.include?(layer)} : files
      images = [@type.sqfs, @type.img].include?(type) ? images.sort :
        images.sort_by{|x| x[/-(\d+\.\d+\.\d+).*/, 1].split('.').map{|y| y.to_i}}.reverse

      # Add file size to each entry
      images.each{|x| image_maps[x] = File.size(x)}
    end

    # Print result for single search
    if layer and image_maps.keys.first
      puts("Located '#{live ? 'live' : 'disk'}' image #{image_maps.keys.first}".colorize(:cyan))
    elsif layer and die
      !puts("Could not find image type '#{type}' for '#{layer}'".colorize(:red)) and exit
    end

    return image_maps
  end

  # Relocate the tracking files
  # @param layer_work [path] directory to get tracking files from
  # @param restore [bool] move the relocated files back to their original location
  # @returns image matching the version
  def relocate_tracking_files(layer_work, restore:false)
    digests = File.join(layer_work, 'digests')
    packages = File.join(layer_work, 'packages')
    changed = File.join(layer_work, 'changed')
    if not restore
      FileUtils.mv(digests, @tmp_dir) if File.exist?(digests)
      FileUtils.mv(packages, @tmp_dir) if File.exist?(packages)
      FileUtils.mv(changed, @tmp_dir) if File.exist?(changed)
    end

    _digests = File.join(@tmp_dir, File.basename(digests))
    _packages = File.join(@tmp_dir, File.basename(packages))
    _changed = File.join(@tmp_dir, File.basename(changed))
    if restore
      FileUtils.mv(_digests, layer_work) if File.exist?(_digests)
      FileUtils.mv(_packages, layer_work) if File.exist?(_packages)
      FileUtils.mv(_changed, layer_work) if File.exist?(_changed)
    end
  end

  # Get layer dependencies
  # @param layer [string] the layer to get dependencies for
  # @returns list of layers (e.g. heavy => heavy, lite, shell, base)
  def getlayers(layer)
    layers = [layer]
    return layers if layer == @k.build
    !puts("Error: invalid layer '#{layer}'".colorize(:red)) and
      exit if not @spec[@k.layers].find{|x| x[@k.name] == layer}

    _layer = layer
    while _layer
      _layer = @spec[@k.layers].find{|x| x[@k.name] == _layer}[@k.base]
      layers << _layer if _layer
    end

    return layers
  end

  # Get layer yaml by layer name
  # @param layer [string] layer name to get yaml for
  # @returns yaml for the indicated layer
  def getlayer(layer)

    # Get yaml for the given layer
    layer = layer == @k.build ? @spec[@k.build] : @spec[@k.layers].find{|x| x[@k.name] == layer}
    !puts("Error: invalid layer '#{layer}'".colorize(:red)) and exit if not layer

    # Resolve templating for the given layer
    vars = layer[@k.vars] ? @vars.to_h.merge(layer[@k.vars]) : @vars
    layer = layer.erb(vars)

    return layer
  end

end

#-------------------------------------------------------------------------------
# Main entry point
#-------------------------------------------------------------------------------
if __FILE__ == $0
  app = 'reduce'
  reduce = Reduce.new
  version = reduce.instance_variable_get(:@vars).release
  examples = "Examples:\n".colorize(:green)
  examples += "Full ISO Build: sudo ./#{app} clean build --iso-full --spec=personal\n".colorize(:green)
  examples += "Rebuild initramfs: sudo ./#{app} clean build --initramfs --iso\n".colorize(:green)
  examples += "Build k8snode layer: sudo ./#{app} clean build --layers=k8snode --iso\n".colorize(:green)
  examples += "Pack k8snode layer: ./#{app} pack --layers=k8snode\n".colorize(:green)
  examples += "Deploy nodes: sudo ./#{app} deploy --layer=k8snode --nodes=10,11,12\n".colorize(:green)
  examples += "Deploy container: sudo ./#{app} deploy --run --layer=build\n".colorize(:green)
  examples += "\n"

  opts = Cmds.new(app, version, examples)
  opts.add('info', 'List build info', [])
  opts.add('list', 'List out components', [
    CmdOpt.new('--all', 'List all components'),
    CmdOpt.new('--boxes', 'List all boxes'),
    CmdOpt.new('--isos', 'List all isos'),
    CmdOpt.new('--images', 'List all docker images'),
    CmdOpt.new('--raw', 'Automation suitable output'),
  ])
  opts.add('clean', 'Clean ISO components', [
    CmdOpt.new('--all', 'Clean all components'),
    CmdOpt.new('--pacman', 'Clean pacman cache'),
    CmdOpt.new('--initramfs', 'Clean initramfs image'),
    CmdOpt.new('--isolinux', 'Clean isolinux boot'),
    CmdOpt.new('--layers=x,y,z', 'Clean given layers', type:Array),
    CmdOpt.new('--iso', 'Clean bootable ISO'),
    CmdOpt.new('--iso-full', 'Clean bootable ISO and all machine layers'),
    CmdOpt.new('--vms', 'Clean VMs that are no longer deployed'),
  ])
  opts.add('build', 'Build ISO components', [
    CmdOpt.new('--spec=SPEC', 'Build from the given spec', type:String, required:true),
    CmdOpt.new('--initramfs', 'Build initramfs image'),
    CmdOpt.new('--isolinux', 'Build isolinux boot'),
    CmdOpt.new('--layers=x,y,z', 'Build given layers', type:Array),
    CmdOpt.new('--iso', 'Build USB bootable ISO with existing layers'),
    CmdOpt.new('--iso-full', 'Build USB bootable ISO with all machine layers')
  ])
  opts.add('pack', 'Pack ISO layers into vagrant boxes', [
    CmdOpt.new('--all', 'Pack all layers'),
    CmdOpt.new('--layers=x,y,z', 'Pack given layers', type:Array),
    CmdOpt.new('--disksize=DISKSIZE', 'Set the disk size in MB e.g. 10000', type:String),
    CmdOpt.new('--force', 'Pack the given layer/s even if they already exists'),
  ])
  opts.add('deploy', 'Deploy VMs or containers', [
    CmdOpt.new('--layer=LAYER', 'Deploy a specific layer VM', type:String, required:true),
    CmdOpt.new('--name=NAME', 'Give a name to the specific node being deployed', type:String),
    CmdOpt.new('--run', 'Run default container run'),
    CmdOpt.new('--exec=CMD', 'Specific command to run in container', type:String),
    CmdOpt.new('--nodes=x,y,z', 'Comma delimited list of last octet IPs (e.g. 10,11,2)', type:Array),
    CmdOpt.new('--force', 'Deploy the given layer/s even if already exists'),
    CmdOpt.new('--ipv6', 'Enable ipv6 on the given nodes'),
    CmdOpt.new('--vagrantfile', 'Export the Vagrantfile only'),
  ])
  opts.parse!

  # Execute
  puts(opts.banner) unless opts[:raw]

  # Execute 'info' command
  reduce.info if opts[:info]

  # Execute 'list' command
  reduce.list(boxes: opts[:boxes], isos: opts[:isos], images: opts[:images], all: opts[:all]) if opts[:list]

  # Execute 'clean' command
  reduce.clean(pacman: opts[:pacman], initramfs: opts[:initramfs], isolinux: opts[:isolinux],
    layers: opts[:layers], iso: opts[:iso], vms: opts[:vms], all: opts[:all],
    isofull: opts[:isofull]) if opts[:clean]

  # Execute 'build' command
  reduce.build(opts[:spec], initramfs: opts[:initramfs], isolinux: opts[:isolinux],
    layers: opts[:layers], iso: opts[:iso], isofull: opts[:isofull]) if opts[:build]

  # Execute 'pack' command
  reduce.pack(opts[:layers], disksize: opts[:disksize], force: opts[:force]) if opts[:pack]

  # Execute 'deploy' command
  reduce.deploy(opts[:layer], name: opts[:name], run: opts[:run], exec: opts[:exec], nodes: opts[:nodes],
    ipv6: opts[:ipv6], vagrantfile: opts[:vagrantfile], force: opts[:force]) if opts[:deploy]
end

# vim: ft=ruby:ts=2:sw=2:sts=2
